{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f1881e",
   "metadata": {},
   "source": [
    "# Text guided image synthesis - Part 1: preparing enviornment\n",
    "\n",
    "In this notebook we install all dependencies and download AI models for this project.\n",
    "\n",
    "## Assumptions\n",
    "\n",
    " - We run on linux.\n",
    " - Apt package is available.\n",
    " - We are root.\n",
    " - torchvision pytorch and nvidia drivers are installed.\n",
    " - Jupyter notebook or jupyter lab is installed.\n",
    "\n",
    "This is essentially setup that we have if we run docker image from pytorch (https://hub.docker.com/r/pytorch/pytorch/).\n",
    "\n",
    "## Dependencies from apt\n",
    "\n",
    "We need to have curl and git if it is not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff700c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.9).\n",
      "The following NEW packages will be installed:\n",
      "  curl libcurl4 wget\n",
      "0 upgraded, 3 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 694 kB of archives.\n",
      "After this operation, 2007 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 wget amd64 1.19.4-1ubuntu2.2 [316 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl4 amd64 7.58.0-2ubuntu3.16 [220 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 curl amd64 7.58.0-2ubuntu3.16 [159 kB]\n",
      "Fetched 694 kB in 0s (1749 kB/s)[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package wget.\n",
      "(Reading database ... 9772 files and directories currently installed.)\n",
      "Preparing to unpack .../wget_1.19.4-1ubuntu2.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking wget (1.19.4-1ubuntu2.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libcurl4:amd64.\n",
      "Preparing to unpack .../libcurl4_7.58.0-2ubuntu3.16_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libcurl4:amd64 (7.58.0-2ubuntu3.16) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package curl.\n",
      "Preparing to unpack .../curl_7.58.0-2ubuntu3.16_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking curl (7.58.0-2ubuntu3.16) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up libcurl4:amd64 (7.58.0-2ubuntu3.16) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up wget (1.19.4-1ubuntu2.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up curl (7.58.0-2ubuntu3.16) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "! apt install -y curl wget git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19373e",
   "metadata": {},
   "source": [
    "## Install required packages using pip\n",
    "\n",
    "(Pip as to be installed)\n",
    "\n",
    "We install:\n",
    "\n",
    " - taming transformes paper source code\n",
    " - tensorflow (for superresolution)\n",
    " - Image Superresolution package\n",
    " - CLIP source code\n",
    " - pytorch lightning\n",
    " - omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df633b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting omegaconf\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 2.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
      "\u001b[K     |████████████████████████████████| 582 kB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 497.6 MB 2.4 kB/s  eta 0:00:01    |█▋                              | 25.4 MB 30.8 MB/s eta 0:00:16     |███████▊                        | 119.4 MB 52.9 MB/s eta 0:00:08     |███████████▏                    | 174.2 MB 52.9 MB/s eta 0:00:07     |█████████████████▏              | 266.8 MB 38.2 MB/s eta 0:00:07     |██████████████████████████▉     | 416.6 MB 49.0 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 59.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.8/site-packages (from omegaconf) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.21.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 44.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.0.0\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: torch>=1.8.* in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.11.0)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
      "\u001b[K     |████████████████████████████████| 398 kB 40.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.62.3)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 23.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 8.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 6.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 43.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 42.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 34.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 29.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 28.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 42.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 46.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.27.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 31.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 37.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.1.1-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 39.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 41.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 33.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 6.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 39.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 5.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 34.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 40.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 57.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 51.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, termcolor\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=44546da9a3492c89f4e5e89d1164883477bf4edbf05446810815cd92d76e8a3c\n",
      "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=843f97abfd8039422e9d165267d6580faf558f71c6ccd2031e7b6df2d26f2dda\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built antlr4-python3-runtime termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, multidict, frozenlist, cachetools, yarl, typing-extensions, requests-oauthlib, importlib-metadata, google-auth, async-timeout, aiosignal, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, pyDeprecate, protobuf, markdown, grpcio, google-auth-oauthlib, fsspec, aiohttp, absl-py, wrapt, torchmetrics, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, antlr4-python3-runtime, tensorflow, pytorch-lightning, omegaconf\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "Successfully installed absl-py-1.0.0 aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.8 astunparse-1.6.3 async-timeout-4.0.2 cachetools-5.0.0 flatbuffers-2.0 frozenlist-1.3.0 fsspec-2022.3.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.6.0 importlib-metadata-4.11.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 multidict-6.0.2 oauthlib-3.2.0 omegaconf-2.1.1 opt-einsum-3.3.0 protobuf-3.20.0 pyDeprecate-0.3.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-1.6.0 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 torchmetrics-0.7.3 typing-extensions-4.1.1 werkzeug-2.1.1 wrapt-1.14.0 yarl-1.7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting git+https://github.com/bfirsh/taming-transformers.git\n",
      "  Cloning https://github.com/bfirsh/taming-transformers.git to /tmp/pip-req-build-k8dwtc62\n",
      "  Running command git clone -q https://github.com/bfirsh/taming-transformers.git /tmp/pip-req-build-k8dwtc62\n",
      "  Resolved https://github.com/bfirsh/taming-transformers.git to commit 8ec57d77c125b19f8f6c047496fd0216db3b700f\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from taming-transformers==0.0.1) (1.11.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from taming-transformers==0.0.1) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from taming-transformers==0.0.1) (4.62.3)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch->taming-transformers==0.0.1) (4.1.1)\n",
      "Building wheels for collected packages: taming-transformers\n",
      "  Building wheel for taming-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for taming-transformers: filename=taming_transformers-0.0.1-py3-none-any.whl size=39752 sha256=fb58faba6a78ea8e70f8dae37f817d4d589e0b94643acf3bc0a5a7d95814617b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-88kqpvg3/wheels/ea/8e/b1/8b1923aa20db7da0e49ab487015a328378d0666b422892dede\n",
      "Successfully built taming-transformers\n",
      "Installing collected packages: taming-transformers\n",
      "Successfully installed taming-transformers-0.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-299uwfa5\n",
      "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-299uwfa5\n",
      "  Resolved https://github.com/openai/CLIP.git to commit 40f5484c1c74edd83cb9cf687c6ab92b28d8b656\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 683 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2022.3.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from clip==1.0) (4.62.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from clip==1.0) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from clip==1.0) (0.12.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.8/site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch->clip==1.0) (4.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->clip==1.0) (1.21.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision->clip==1.0) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->clip==1.0) (9.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->clip==1.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->clip==1.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->clip==1.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->clip==1.0) (1.26.7)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369221 sha256=bdee0b41b9d960beb18509075bfb8296bf6f343673c54f31dd29edf2077efb08\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zbt1w6cq/wheels/ab/4f/3a/5e51521b55997aa6f0690e095c08824219753128ce8d9969a3\n",
      "Successfully built clip\n",
      "Installing collected packages: regex, ftfy, clip\n",
      "Successfully installed clip-1.0 ftfy-6.1.1 regex-2022.3.15\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting git+https://github.com/idealo/image-super-resolution.git\n",
      "  Cloning https://github.com/idealo/image-super-resolution.git to /tmp/pip-req-build-oyw4qlsj\n",
      "  Running command git clone -q https://github.com/idealo/image-super-resolution.git /tmp/pip-req-build-oyw4qlsj\n",
      "  Resolved https://github.com/idealo/image-super-resolution.git to commit 3f6498cf1ac4dba162a52c5861aa9d90b7c2fe35\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from ISR==2.2.0) (1.21.2)\n",
      "Requirement already satisfied: tensorflow==2.* in /opt/conda/lib/python3.8/site-packages (from ISR==2.2.0) (2.8.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from ISR==2.2.0) (4.62.3)\n",
      "Collecting pyaml\n",
      "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting h5py==2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 39.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from h5py==2.10.0->ISR==2.2.0) (1.16.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (13.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (4.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (0.24.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (1.44.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (58.0.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (0.5.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/lib/python3.8/site-packages (from tensorflow==2.*->ISR==2.2.0) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.*->ISR==2.2.0) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (2.1.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (2.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.*->ISR==2.2.0) (3.2.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.8/site-packages (from imageio->ISR==2.2.0) (9.0.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from pyaml->ISR==2.2.0) (6.0)\n",
      "Building wheels for collected packages: ISR\n",
      "  Building wheel for ISR (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ISR: filename=ISR-2.2.0-py3-none-any.whl size=33513 sha256=2808954420bc89969a534b8fb0f43fe80000092045b890a21cca5686a496bf25\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-v_dnflxa/wheels/dc/fc/9d/b8d248780705e5bdf35cc9fbaa30f0f2c583e4f02275e73d27\n",
      "Successfully built ISR\n",
      "Installing collected packages: h5py, pyaml, imageio, ISR\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.6.0\n",
      "    Uninstalling h5py-3.6.0:\n",
      "      Successfully uninstalled h5py-3.6.0\n",
      "Successfully installed ISR-2.2.0 h5py-2.10.0 imageio-2.16.1 pyaml-21.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install omegaconf pytorch-lightning tensorflow\n",
    "!pip install git+https://github.com/bfirsh/taming-transformers.git\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install git+https://github.com/idealo/image-super-resolution.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d55a3",
   "metadata": {},
   "source": [
    "## Download AI models\n",
    "\n",
    "We will download them to /weights path.\n",
    "\n",
    "First we download CLIP model. We will download the best performing model (ViT-B-32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86187fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  337M  100  337M    0     0  32.4M      0  0:00:10  0:00:10 --:--:-- 32.6M\n"
     ]
    }
   ],
   "source": [
    "!mkdir weights\n",
    "!curl -o weights/ViT-B-32.pt https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfdaf4c",
   "metadata": {},
   "source": [
    "Now we download VQGAN model. We choose model depending on what we plan to generate.\n",
    "Each cell downloads one model. All models take around 17.7GB so it is recommended to download only the ones you plan to use.\n",
    "\n",
    "Imagenet 16384 model - Imagenet is a dataset that contains images of 16384 different objects. Model will be good for generating objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b03178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "100  934M  100  934M    0     0  14.5M      0  0:01:04  0:01:04 --:--:-- 14.8M   37  351M    0     0  13.8M      0  0:01:07  0:00:25  0:00:42 14.9M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   692  100   692    0     0   1272      0 --:--:-- --:--:-- --:--:--  1272\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o weights/vqgan_imagenet_f16_16384.ckpt -C - 'https://heibox.uni-heidelberg.de/f/867b05fc8c4841768640/?dl=1'\n",
    "!curl -L -o weights/vqgan_imagenet_f16_16384.yaml -C - 'https://heibox.uni-heidelberg.de/f/274fb24ed38341bfa753/?dl=1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6be287",
   "metadata": {},
   "source": [
    "COCO model - Dataset contains objects in everyday environment. Another model good for generating objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3155d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1980    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 100  1980    0     0   2625      0 --:--:-- --:--:-- --:--:--  2625\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 8045M  100 8045M    0     0  29.6M      0  0:04:31  0:04:31 --:--:-- 26.4M  32 2618M    0     0  29.3M      0  0:04:34  0:01:29  0:03:05 29.3M7589M    0     0  29.6M      0  0:04:31  0:04:16  0:00:15 31.5M     0  29.6M      0  0:04:31  0:04:19  0:00:12 33.0M 96 7784M    0     0  29.6M      0  0:04:31  0:04:22  0:00:09 32.7M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o weights/coco.yaml -C - 'https://dl.nmkd.de/ai/clip/coco/coco.yaml'\n",
    "!curl -L -o weights/coco.ckpt -C - 'https://dl.nmkd.de/ai/clip/coco/coco.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e793314",
   "metadata": {},
   "source": [
    "FacesHQ model - Dataset containing faces. Model will be good for generating portraits (or more specifically monsters because this method does not generate good portraits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bce665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1451  100  1451    0     0   1545      0 --:--:-- --:--:-- --:--:--  1545\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3789M  100 3789M    0     0  32.3M      0  0:01:57  0:01:57 --:--:-- 59.7MM\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o weights/faceshq.yaml -C - 'https://drive.google.com/uc?export=download&id=1fHwGx_hnBtC8nsq7hesJvs-Klv-P0gzT'\n",
    "!curl -L -o weights/faceshq.ckpt -C - 'https://app.koofr.net/content/links/a04deec9-0c59-4673-8b37-3d696fe63a5d/files/get/last.ckpt?path=%2F2020-11-13T21-41-45_faceshq_transformer%2Fcheckpoints%2Flast.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be854456",
   "metadata": {},
   "source": [
    "Wikiart model - Dataset containing paintings. Model will be good for generating paintings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "166c81d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  958M  100  958M    0     0  7414k      0  0:02:12  0:02:12 --:--:-- 7680k 0     0  7379k      0  0:02:13  0:01:24  0:00:49 7606k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   920  100   920    0     0   2030      0 --:--:-- --:--:-- --:--:--  2026\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o weights/wikiart_16384.ckpt -C - 'http://eaidata.bmk.sh/data/Wikiart_16384/wikiart_f16_16384_8145600.ckpt'\n",
    "!curl -L -o weights/wikiart_16384.yaml -C - 'http://eaidata.bmk.sh/data/Wikiart_16384/wikiart_f16_16384_8145600.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc66f37",
   "metadata": {},
   "source": [
    "Flickr dataset - Dataset containing a lot of landscapes. Model will be good for generating landscapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3beb0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1603  100  1603    0     0   2852      0 --:--:-- --:--:-- --:--:--  2852\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 4066M  100 4066M    0     0  14.9M      0  0:04:32  0:04:32 --:--:-- 14.9MM    0     0  14.8M      0  0:04:32  0:02:49  0:01:43 14.9M  72 2960M    0     0  14.8M      0  0:04:32  0:03:18  0:01:14 14.9M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o weights/sflckr.yaml -C - 'https://heibox.uni-heidelberg.de/d/73487ab6e5314cb5adba/files/?p=%2Fconfigs%2F2020-11-09T13-31-51-project.yaml&dl=1'\n",
    "!curl -L -o weights/sflckr.ckpt -C - 'https://heibox.uni-heidelberg.de/d/73487ab6e5314cb5adba/files/?p=%2Fcheckpoints%2Flast.ckpt&dl=1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5becdc",
   "metadata": {},
   "source": [
    "Superresolution models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "505b1132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-27 18:32:50--  https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rdn-C3-D10-G64-G064-x2/PSNR-driven/rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5\n",
      "Resolving public-asai-dl-models.s3.eu-central-1.amazonaws.com (public-asai-dl-models.s3.eu-central-1.amazonaws.com)... 52.219.170.46\n",
      "Connecting to public-asai-dl-models.s3.eu-central-1.amazonaws.com (public-asai-dl-models.s3.eu-central-1.amazonaws.com)|52.219.170.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10694096 (10M) [binary/octet-stream]\n",
      "Saving to: ‘rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5’\n",
      "\n",
      "rdn-C3-D10-G64-G064 100%[===================>]  10.20M  3.19MB/s    in 3.2s    \n",
      "\n",
      "2022-03-27 18:32:54 (3.19 MB/s) - ‘rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5’ saved [10694096/10694096]\n",
      "\n",
      "--2022-03-27 18:32:54--  https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rdn-C6-D20-G64-G064-x2/ArtefactCancelling/rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5\n",
      "Resolving public-asai-dl-models.s3.eu-central-1.amazonaws.com (public-asai-dl-models.s3.eu-central-1.amazonaws.com)... 52.219.170.46\n",
      "Connecting to public-asai-dl-models.s3.eu-central-1.amazonaws.com (public-asai-dl-models.s3.eu-central-1.amazonaws.com)|52.219.170.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 66071288 (63M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5’\n",
      "\n",
      "rdn-C6-D20-G64-G064 100%[===================>]  63.01M  5.29MB/s    in 16s     \n",
      "\n",
      "2022-03-27 18:33:11 (4.03 MB/s) - ‘rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5’ saved [66071288/66071288]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!curl -o weights/rdn-C6-D20-G64-G064-x2_PSNR_epoch086.hdf5 https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rdn-C6-D20-G64-G064-x2/PSNR-driven/rdn-C6-D20-G64-G064-x2_PSNR_epoch086.hdf5\n",
    "!curl -o weights/rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5 https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rdn-C3-D10-G64-G064-x2/PSNR-driven/rdn-C3-D10-G64-G064-x2_PSNR_epoch134.hdf5\n",
    "!curl -o weights/rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5 https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rdn-C6-D20-G64-G064-x2/ArtefactCancelling/rdn-C6-D20-G64-G064-x2_ArtefactCancelling_epoch219.hdf5\n",
    "!curl -o weights/rrdn-C4-D3-G32-G032-T10-x4_epoch299.hdf5 https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/ISR/rrdn-C4-D3-G32-G032-T10-x4-GANS/rrdn-C4-D3-G32-G032-T10-x4_epoch299.hdf5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
