{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be303362-5d16-4efa-b501-fc70ada41d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe68add5-0f71-45c5-9cca-026b2244707b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f8e7b862ed0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12c6625-b58b-4de8-a7d3-ea332a687829",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "class ImageLoader:\n",
    "    def __init__(self, device, preprocessor):\n",
    "        self.device = device\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def __call__(self, filepath):\n",
    "        img = Image.open(filepath)\n",
    "        return self.preprocessor(img).unsqueeze(0).to(self.device)\n",
    "\n",
    "loader = ImageLoader(device, preprocess)\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2f2d3c3-03bf-49ed-b378-c45630b845bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clip.tokenize([\"picture\", \"of\", \"a building\", \"a computer\", \"a lake\", \"a mountain\"]).to(device)\n",
    "img = loader(\"images/lake.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8018ae00-9ccd-46a3-b4a9-982e9ef05e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = model.encode_image(img)\n",
    "text_features = model.encode_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "914a3c3f-97b7-4187-a37e-748498fcf5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa46ce16-3201-4bfb-9883-0009db90adcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9e42395-cd93-44ce-96a3-39202bd55532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.2344],\n",
       "        [12.7578],\n",
       "        [10.7422],\n",
       "        [10.4141],\n",
       "        [10.1094],\n",
       "        [10.5000]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c3782ea-da73-48a2-8208-2ae628a35ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ performs matrix multiplication\n",
    "# Cosine similarity is equivalent of dot product after normalization of embeddings\n",
    "\n",
    "# Normalize all vectors, for text every vector is normalized separately.\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5ad08c1-5399-40df-bb92-0432b2b6251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between image and all text embeddings\n",
    "similarity = 100 * image_features @ text_features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b532f9d1-6996-4c81-9358-185a1d20e016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.8289e-03, 2.1782e-03, 8.0585e-05, 2.1565e-04, 9.3555e-01, 5.6183e-02]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99811570-7238-452f-895d-53ae96c8a067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
